{
    "env": {
        "config_file": "reward_norm/env_config_guidance_MR_medium_mu_chi_b_1.json",
        "custom_config": {},
        "normarlize_reward": "reward_scaling_cluster"
    },
    "rl": {
        "experiment_name": "reward_norm/medium_mu_chi_b_1_guidance/ppo/reward_scaling_cluster/128_128_2e8steps_seed_3",
        "seed": 22,
        "seed_in_train_env": 23,
        "seed_in_callback_env": 25,
        "train_steps": 2e8,
        "net_arch": [128, 128],
        "batch_size": 4096,
        "gamma": 0.995,
        "rollout_process_num": 64,
        "evaluate_process_num": 32,
        "callback_process_num": 32,
        "learning_rate": 3e-4,
        "evaluate_frequence": 2048,
        "__evaluate_frequence": "多少次env.step()评估一次，如果设置为1000，且VecEnv有72个并行环境，所以实际相当于72*1000次step，评估一次",
        "evaluate_nums_in_evaluation": 30,
        "__evaluate_nums_in_evaluation": "使用evaluate_nums_in_evaluation * evaluate_process_num个episodes评估策略",
        "evaluate_nums_in_callback": 3,
        "__evaluate_nums_in_callback": "使用evaluate_nums_in_callback * evaluate_process_num个episodes评估策略",
        "save_checkpoint_every_n_timesteps": 4000000,
        "device": "cpu"
    }
}