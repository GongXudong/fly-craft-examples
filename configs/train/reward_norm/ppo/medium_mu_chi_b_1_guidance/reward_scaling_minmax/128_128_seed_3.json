{
    "env": {
        "config_file": "reward_norm/env_config_guidance_MR_medium_mu_chi_b_1.json",
        "custom_config": {},
        "normarlizer": {
            "use": true,
            "type": "reward_scaling_minmax",
            "dg_search_radius": 3.0,
            "default_max_return": -100.0,
            "reference_file_list": [
                "configs/train/reward_norm/ppo/medium_mu_chi_b_1_guidance/reward_scaling_minmax/rl_bc_evaluation_res/iter_4_seed_1.csv",
                "configs/train/reward_norm/ppo/medium_mu_chi_b_1_guidance/reward_scaling_minmax/rl_bc_evaluation_res/iter_4_seed_2.csv",
                "configs/train/reward_norm/ppo/medium_mu_chi_b_1_guidance/reward_scaling_minmax/rl_bc_evaluation_res/iter_4_seed_3.csv",
                "configs/train/reward_norm/ppo/medium_mu_chi_b_1_guidance/reward_scaling_minmax/rl_bc_evaluation_res/iter_4_seed_4.csv",
                "configs/train/reward_norm/ppo/medium_mu_chi_b_1_guidance/reward_scaling_minmax/rl_bc_evaluation_res/iter_4_seed_5.csv"
            ]
        }
    },
    "rl": {
        "experiment_name": "reward_norm/medium_mu_chi_b_1_guidance/ppo/reward_scaling_minmax/128_128_2e8steps_seed_3",
        "seed": 22,
        "seed_in_train_env": 26,
        "seed_in_callback_env": 29,
        "train_steps": 2e8,
        "net_arch": [128, 128],
        "batch_size": 4096,
        "gamma": 0.995,
        "rollout_process_num": 64,
        "evaluate_process_num": 32,
        "callback_process_num": 32,
        "learning_rate": 3e-4,
        "evaluate_frequence": 2048,
        "__evaluate_frequence": "多少次env.step()评估一次，如果设置为1000，且VecEnv有72个并行环境，所以实际相当于72*1000次step，评估一次",
        "evaluate_nums_in_evaluation": 30,
        "__evaluate_nums_in_evaluation": "使用evaluate_nums_in_evaluation * evaluate_process_num个episodes评估策略",
        "evaluate_nums_in_callback": 3,
        "__evaluate_nums_in_callback": "使用evaluate_nums_in_callback * evaluate_process_num个episodes评估策略",
        "save_checkpoint_every_n_timesteps": 4000000,
        "device": "cpu"
    }
}