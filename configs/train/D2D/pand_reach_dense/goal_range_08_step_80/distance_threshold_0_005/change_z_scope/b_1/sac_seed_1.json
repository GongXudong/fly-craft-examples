{
    "rl_common": {
        "net_arch": [256, 256],
        "gamma": 0.95,
        "batch_size": 256,
        "buffer_size": 2e5,
        "rollout_process_num": 1,
        "evaluate_process_num": 8,
        "callback_process_num": 8,
        "gradient_steps": 1,
        "eval_freq": 1e3,
        "n_eval_episodes": 96,
        "use_her": true
    },
    
    "rl_train": [{
        "env": {
            "id": "my-reach",
            "__help": "goal_range, distance_threshold, max_episode_steps只用于记录，环境的实际配置需在脚本中指定！！！",
            "goal_range": 0.8,
            "distance_threshold": 0.01,
            "max_episode_steps": 80,
            "reward_type": "dense", 
            "control_type": "joints",
            "normalize": false,
            "b": 1.0
        },
        "rl": {
            "experiment_name": "D2D/panda_reach_dense/goal_range_08_step_80/distance_threshold_0_005/change_z_scope/her/b_1/sac_her_10hz_128_128_b_1_1e5steps_seed_1_singleRL",
            "seed": 51,
            "seed_in_train_env": 26,
            "seed_in_callback_env": 69,
            "train_steps": 1e5,
            "learning_rate": 3e-4,
            "learning_starts": 1000,
            "reset_policy": false,
            "relabel_replay_buffer": false,
            "has_trained": false
        }
    }]

}