#!/bin/bash

# algo: epsilon 0.1 reg 0  eval: epsilon 0.01
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.01 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_GA_KL_0_0003_10_noise_0_01.csv

# algo: epsilon 0.1 reg 0  eval: epsilon 0.1
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.1 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_GA_KL_0_0003_10_noise_0_1.csv

# algo: epsilon 0.1 reg 0  eval: epsilon 0.5
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.5 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_GA_KL_0_0003_10_noise_0_5.csv

# algo: epsilon 0.1 reg 0  eval: epsilon 1.0
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 1.0 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_GA_KL_0_0003_10_noise_1.csv


# algo: epsilon 0.1 reg 0.0001  eval: epsilon 0.01
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_0001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.01 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_0001_N_16_GA_KL_0_0003_10_noise_0_01.csv

# algo: epsilon 0.1 reg 0.0001  eval: epsilon 0.1
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_0001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.1 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_0001_N_16_GA_KL_0_0003_10_noise_0_1.csv

# algo: epsilon 0.1 reg 0.0001  eval: epsilon 0.5
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_0001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.5 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_0001_N_16_GA_KL_0_0003_10_noise_0_5.csv

# algo: epsilon 0.1 reg 0.0001  eval: epsilon 1.0
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_0001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.0001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 1.0 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_0001_N_16_GA_KL_0_0003_10_noise_1.csv


# algo: epsilon 0.1 reg 0.001  eval: epsilon 0.01
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.01 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_001_N_16_GA_KL_0_0003_10_noise_0_01.csv

# algo: epsilon 0.1 reg 0.001  eval: epsilon 0.1
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.1 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_001_N_16_GA_KL_0_0003_10_noise_0_1.csv

# algo: epsilon 0.1 reg 0.001  eval: epsilon 0.5
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.5 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_001_N_16_GA_KL_0_0003_10_noise_0_5.csv

# algo: epsilon 0.1 reg 0.001  eval: epsilon 1.0
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_001_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.001 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 1.0 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_001_N_16_GA_KL_0_0003_10_noise_1.csv


# algo: epsilon 0.1 reg 0.01  eval: epsilon 0.01
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_01_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.01 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.01 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_01_N_16_GA_KL_0_0003_10_noise_0_01.csv

# algo: epsilon 0.1 reg 0.01  eval: epsilon 0.1
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_01_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.01 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.1 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_01_N_16_GA_KL_0_0003_10_noise_0_1.csv

# algo: epsilon 0.1 reg 0.01  eval: epsilon 0.5
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_01_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.01 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.5 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_01_N_16_GA_KL_0_0003_10_noise_0_5.csv

# algo: epsilon 0.1 reg 0.01  eval: epsilon 1.0
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_01_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.01 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 1.0 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_01_N_16_GA_KL_0_0003_10_noise_1.csv


# algo: epsilon 0.1 reg 0.1  eval: epsilon 0.01
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.01 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.1 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_1_N_16_GA_KL_0_0003_10_noise_0_01.csv

# algo: epsilon 0.1 reg 0.1  eval: epsilon 0.1
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.1 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.1 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_1_N_16_GA_KL_0_0003_10_noise_0_1.csv

# algo: epsilon 0.1 reg 0.1  eval: epsilon 0.5
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.1 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.5 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_1_N_16_GA_KL_0_0003_10_noise_0_5.csv

# algo: epsilon 0.1 reg 0.1  eval: epsilon 1.0
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_0_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 0.1 --algo-reg 0.1 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 1.0 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_0_1_N_16_GA_KL_0_0003_10_noise_1.csv


# algo: epsilon 0.1 reg 1.0  eval: epsilon 0.01
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 1.0 --algo-reg 0.1 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.01 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_1_N_16_GA_KL_0_0003_10_noise_0_01.csv

# algo: epsilon 0.1 reg 1.0  eval: epsilon 0.1
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 1.0 --algo-reg 0.1 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.1 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_1_N_16_GA_KL_0_0003_10_noise_0_1.csv

# algo: epsilon 0.1 reg 1.0  eval: epsilon 0.5
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 1.0 --algo-reg 0.1 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 0.5 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_1_N_16_GA_KL_0_0003_10_noise_0_5.csv

# algo: epsilon 0.1 reg 1.0  eval: epsilon 1.0
python train_scripts/disc/evaluate/evaluate_ppo_with_gradient_ascent_attacker.py --env-config configs/env/D2D/env_config_for_ppo_medium_b_05.json --env-flag-str Medium-05 --algo-class SmoothGoalPPO --algo-ckpt-dir checkpoints/disc/medium/ppo/epsilon_0_1_reg_1_N_16/128_128_2e8steps_seed_{0} --algo-ckpt-model-name best_model --algo-seeds 1 2 3 4 5 --algo-flag-str PPO --algo-epsilon 1.0 --algo-reg 0.1 --evaluate-dg-num 300 --evaluate-gradient-ascent-lr 0.0003 --evaluate-gradient-optimization-steps 10 --evaluate-noise-base 10.0 3.0 3.0 --evaluate-noise-multiplier 1.0 --attacker-flag-str Gradient-Ascent[KL]-0.0003-10 --policy-distance-measure-func KL --res-file-save-name train_scripts/disc/evaluate/results/res_log_medium2_ppo_epsilon_0_1_reg_1_N_16_GA_KL_0_0003_10_noise_1.csv
